# Identify Critical Flows and Author NHP BDD Scenarios

## Role
Assume the role of an Automation QA (Quality Assurance) Engineer specialized in crafting precise, testable Gherkin scenarios.

## Objective
Find the most critical product flows and produce comprehensive BDD scenarios for their Non-Happy Paths (NHP), including at least one baseline happy path for context. No architecture or C4 diagrams are required.

## Inputs

Read the below documents in full.

- Existing feature BDD spec: `docs/spec_scenarios/[<FEATURE>]_spec.md` (previously generated Gherkin scenarios for the feature).
- User manual section(s): `docs/user_manual/[<FEATURE>].md` relevant to the feature.
- Mock data: `docs/workflow/inputs/mock_data.md` (use only values defined there).

## Task

1) Open the corresponding `docs/spec_scenarios/[<FEATURE>]_spec.md` and select the existing happy path scenario(s) that represent the critical flow. Generate `flow_slug` by converting the chosen scenario or feature name to kebab-case.

2) For the chosen flow, enumerate key steps and select 1–3 plausible failure events with high impact/likelihood (e.g., IdP latency/timeout, database write contention, validation error, message queue delay, permission denial).

3) For each failure event, write precise Gherkin scenarios that capture:
     - Preconditions, role/permissions, and exact UI context.
     - A single concrete user action per scenario (chain sub-steps with And if needed).
     - Immediate, visible system response (banner text, disabled state, error copy, loading indicator behavior).
     - Persisted state or navigation if applicable.

4) Include at least:
    - Reference to the existing happy path scenario for the critical flow (do not duplicate it).
    - 2+ new negative/edge scenarios covering validation and authorization/timeouts.

5) Use only entities/IDs from `mock_data.md`. If a value is unavailable, parameterize via Scenario Outline with Examples drawn from mock data.

## Authoring Rules (align with 2.1 Precise BDD Guide)

- Exactly one Given, one When, one Then per scenario; extend with And lines if needed.
- Avoid vague verbs; specify control names, locations, data-testids/selectors where available.
- For async actions, specify waiting conditions and what ends them.
- Keep messages exact when documented; note color/icon if specified.
- Verify persistency by refreshing or re-navigating when applicable.

## Output Location and Naming

- Prefer appending to the existing feature file: `docs/spec_scenarios/[<FEATURE>]_spec.md` under a new section heading: `## Critical Flow: <scenario or feature name> — NHP Scenarios`.
- If separation is desired, alternatively write to: `docs/spec_scenarios/nhp_<flow_slug>.md`. If creating a new file, keep the original Feature title as the first line.

## Scenario Template

Use this template for each scenario (newline And style allowed; do not mix inline and newline And in one scenario). When appending to an existing feature file, do not duplicate the `Feature:` header:

```
# Feature: <Keep the original feature title>  
# (Include only when creating a new file, not when appending to an existing feature spec.)

@critical @nhp @<tag-for-failure>
Scenario: <Concise, outcome-oriented title>
    Given <explicit initial state and role> 
    And <concrete data setup from mock_data.md>
    When <the user performs one concrete action>
    And <optional additional action or confirmation>
    Then <immediate, visible, verifiable outcome>
    And <persisted state or navigation if applicable>

# Use Scenario Outline only when varying inputs from mock_data.md
Scenario Outline: <Title with parameterized values>
    Given <state using <param> from mock_data.md>
    When <single action>
    Then <outcome>

Examples:
    | param |
    | value-from-mock-data |
```

## Coverage Checklist (apply to the set for the flow)

- Includes 1 happy path baseline and at least 2 negative/edge scenarios.
- Covers validation error(s) and authorization/timeout case(s).
- Uses only values from `mock_data.md`; IDs and labels match exactly.
- Each scenario has one Given/When/Then with clear And lines; outcomes are visible and testable.
- Persistency verified where relevant (post-refresh, re-open page, etc.).
- Cross-feature dependencies (e.g., person must exist before assignment) are referenced clearly.

## Example (illustrative only — replace with your flow)

```
# Feature: Manage Projects

@critical @happy
Scenario: Create a new project successfully
    Given the project manager user "user-pm-1" is on the Projects page with the New Project dialog open
    And the form is empty and the Save button is disabled
    When the user enters project name "Project Atlas" and selects client "client-1" and clicks Save
    Then a success banner with text "Project created" is visible and the dialog closes
    And the projects table shows "Project Atlas" sorted by Created date descending

@critical @nhp @validation
Scenario: Prevent project creation without a name
    Given the project manager user "user-pm-1" has the New Project dialog open
    When the user leaves the Name field empty and clicks Save
    Then an inline error with text "Project name is required" is shown under the Name field
    And the Save button remains disabled and no API call is sent

@critical @nhp @auth @timeout
Scenario: Show error when token expires during save
    Given the project manager user "user-pm-1" has the New Project dialog open and the session is expired
    When the user clicks Save
    Then an error banner with text "Your session has expired. Please sign in again." is visible
    And the dialog remains open with unsaved values preserved
```

## Submission

- Commit the updates in `docs/spec_scenarios/[<FEATURE>]_spec.md` under the "Critical Flow — NHP Scenarios" section (preferred), or commit the `nhp_<flow_slug>.md` file to `docs/spec_scenarios/` if you created a separate file.
- Ensure the Coverage Checklist passes before submission.

## Notes

- No C4 or other diagrams are needed. Focus on high-signal BDD scenarios that testers can automate directly.
- When SLOs define timeouts (e.g., p95 ≤ 250 ms), reflect user-visible behavior (spinner, error after 30 s) in Then steps if relevant to the failure.

